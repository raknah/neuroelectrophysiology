{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1abfe81",
   "metadata": {},
   "source": [
    "# 5xFAD Resting State EEG - Simple Processing\n",
    "\n",
    "A minimal notebook that replicates the core processing workflow:\n",
    "1. Extract Open Ephys sessions\n",
    "2. Apply standard preprocessing pipeline\n",
    "3. Save to HDF5 for Julia analysis\n",
    "\n",
    "**Just edit the paths in cell 2 and run all cells!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5efeb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate conda environment and import required modules\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure we're using the spectra conda environment\n",
    "try:\n",
    "    # Check if we're already in the right environment\n",
    "    conda_env = os.environ.get('CONDA_DEFAULT_ENV', 'base')\n",
    "    if conda_env != 'spectra':\n",
    "        print(f\"âš ï¸ Current environment: {conda_env}\")\n",
    "        print(\"ğŸ’¡ Please activate the 'spectra' environment:\")\n",
    "        print(\"   conda activate spectra\")\n",
    "        print(\"   Then restart this notebook\")\n",
    "    else:\n",
    "        print(f\"âœ… Using conda environment: {conda_env}\")\n",
    "except:\n",
    "    print(\"âš ï¸ Could not detect conda environment\")\n",
    "\n",
    "# Add the modules directory to Python path\n",
    "notebook_dir = Path.cwd()\n",
    "if 'notebooks' in str(notebook_dir):\n",
    "    modules_dir = notebook_dir.parent / \"modules\"\n",
    "else:\n",
    "    modules_dir = notebook_dir / \"modules\"\n",
    "sys.path.insert(0, str(modules_dir))\n",
    "\n",
    "# Import openephysextract modules\n",
    "try:\n",
    "    from openephysextract.extractor import Extractor\n",
    "    from openephysextract.preprocess import (\n",
    "        Preprocessor, RemoveBadStep, FilterStep, \n",
    "        DownsampleStep, EpochStep, StandardizeStep\n",
    "    )\n",
    "    from openephysextract.utilities import spreadsheet\n",
    "    print(\"âœ… Imports loaded successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import error: {e}\")\n",
    "    print(\"ğŸ’¡ Make sure you're in the 'spectra' conda environment\")\n",
    "    print(\"   conda activate spectra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663bfc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# CONFIGURATION - EDIT THESE PATHS\n",
    "# ================================\n",
    "\n",
    "# Data paths\n",
    "SOURCE_FOLDER = '/Volumes/STORAGE 1.0/UNIC Research/5xFAD Resting State'\n",
    "OUTPUT_FOLDER = '/Users/fomo/Documents/Research/UNIC Research/Neuroelectrophysiology/5xFAD Resting State/data'\n",
    "NOTES_PATH = '/Users/fomo/Documents/Research/UNIC Research/Neuroelectrophysiology/notes/MICE_LIST_EEG.xlsx'\n",
    "\n",
    "# Experiment settings\n",
    "EXPERIMENT_NAME = '5xFAD Resting State'\n",
    "SAMPLING_RATE = 30000\n",
    "CHANNELS = [3, 4, 5, 6, 7, 8]  # S1 L+R, V1/V2 L+R channels\n",
    "\n",
    "# Processing settings  \n",
    "USE_GPU = True\n",
    "DEVICE = 'mps'  # 'mps' for Apple Silicon, 'cuda' for NVIDIA, 'cpu' for CPU-only\n",
    "\n",
    "print(f\"ğŸ“ Source: {SOURCE_FOLDER}\")\n",
    "print(f\"ğŸ“ Output: {OUTPUT_FOLDER}\")\n",
    "print(f\"ğŸ”§ Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6be741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load experimental metadata\n",
    "print(\"ğŸ“‹ Loading session notes...\")\n",
    "\n",
    "try:\n",
    "    # Try to load notes from Excel file\n",
    "    notes = spreadsheet(\n",
    "        location=os.path.dirname(NOTES_PATH),\n",
    "        name=os.path.basename(NOTES_PATH),\n",
    "        id='Session',\n",
    "        relevant=sorted(os.listdir(SOURCE_FOLDER)),\n",
    "        sheet='MEP'\n",
    "    )\n",
    "    print(f\"âœ… Loaded notes for {len(notes)} sessions\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Could not load notes: {e}\")\n",
    "    print(\"ğŸ“ Will use session names directly\")\n",
    "    notes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b69948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Open Ephys sessions\n",
    "print(\"ğŸ”¬ Extracting sessions from Open Ephys data...\")\n",
    "\n",
    "extractor = Extractor(\n",
    "    source=SOURCE_FOLDER,\n",
    "    experiment=EXPERIMENT_NAME,\n",
    "    sampling_rate=SAMPLING_RATE,\n",
    "    output='/tmp/5xfad_cache',  # Temporary cache location\n",
    "    notes=notes,\n",
    "    channels=CHANNELS\n",
    ")\n",
    "\n",
    "sessions = extractor.extractify(export=False)\n",
    "print(f\"âœ… Extracted {len(sessions)} sessions\")\n",
    "\n",
    "# Show session info\n",
    "for i, session in enumerate(sessions[:3]):  # Show first 3\n",
    "    print(f\"Session {i+1}: {session.session} - {session.data.shape}\")\n",
    "if len(sessions) > 3:\n",
    "    print(f\"... and {len(sessions)-3} more sessions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b952883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipeline\n",
    "print(\"âš™ï¸ Setting up preprocessing pipeline...\")\n",
    "\n",
    "# Define processing steps (same as original notebook)\n",
    "steps = [\n",
    "    RemoveBadStep(std=True, alpha=0.5, beta=0.5, cutoff_pct=90),  # Remove bad channels/epochs\n",
    "    FilterStep(lowcut=0.1, highcut=80, order=4),                 # Bandpass filter 0.1-80 Hz\n",
    "    DownsampleStep(target_fs=100, downsample_raw=True),          # Downsample to 100 Hz\n",
    "    EpochStep(frame=100, stride=10),                             # 1s epochs, 90% overlap\n",
    "    StandardizeStep(method='zscore', per_epoch=True)             # Z-score standardization\n",
    "]\n",
    "\n",
    "# Create preprocessor\n",
    "preprocessor = Preprocessor(\n",
    "    steps=steps,\n",
    "    device=DEVICE,\n",
    "    log=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"âœ… Preprocessing pipeline ready:\")\n",
    "for i, step in enumerate(steps, 1):\n",
    "    print(f\"  {i}. {step.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fb84a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to all sessions\n",
    "print(\"ğŸ”„ Preprocessing sessions...\")\n",
    "\n",
    "processed_sessions = preprocessor.preprocess(sessions, use_gpu=USE_GPU)\n",
    "\n",
    "print(f\"âœ… Preprocessed {len(processed_sessions)} sessions\")\n",
    "\n",
    "# Show processed data info\n",
    "for i, session in enumerate(processed_sessions[:3]):  # Show first 3\n",
    "    data_shape = session.data.processed.shape if hasattr(session.data, 'processed') else session.data.shape\n",
    "    print(f\"Processed {i+1}: {session.session} - {data_shape}\")\n",
    "if len(processed_sessions) > 3:\n",
    "    print(f\"... and {len(processed_sessions)-3} more sessions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e66c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed sessions to HDF5 format\n",
    "print(\"ğŸ’¾ Saving sessions to HDF5...\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "saved_files = []\n",
    "for session in processed_sessions:\n",
    "    output_path = os.path.join(OUTPUT_FOLDER, f'{session.session}.h5')\n",
    "    session.to_hdf5(output_path)\n",
    "    saved_files.append(output_path)\n",
    "    print(f\"ğŸ’¾ Saved: {session.session}.h5\")\n",
    "\n",
    "print(f\"\\nğŸ‰ Processing complete!\")\n",
    "print(f\"ğŸ“ Saved {len(saved_files)} HDF5 files to: {OUTPUT_FOLDER}\")\n",
    "print(f\"\\nğŸ”¬ Ready for Julia analysis!\")\n",
    "print(f\"Load in Julia with: session = from_hdf5(\\\"{saved_files[0]}\\\")\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
