{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:06:11.733650Z",
     "start_time": "2025-07-01T12:06:11.728791Z"
    }
   },
   "source": [
    "import os\n",
    "import dill as pickle\n",
    "import scienceplots\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import importlib\n",
    "\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "import openephysextract\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.style.use(['science', 'grid'])\n",
    "plt.rc('figure', titlesize = 33, figsize = (21, 7), dpi = 210)\n",
    "plt.rc('axes', titlesize = 27, labelsize = 21, titlepad = 21)\n",
    "plt.rc('xtick', labelsize = 17)\n",
    "plt.rc('ytick', labelsize = 17)\n",
    "\n",
    "source = '/Volumes/STORAGE 1.0/UNIC Research/5xFAD Resting State'\n",
    "master = '/Users/fomo/Documents/Research/UNIC Research/Neuroelectrophysiology'\n",
    "experiment = '5xFAD Resting State'\n",
    "destination = os.path.join(master, experiment)\n",
    "local_path = '/Users/fomo/Local Data/5xFAD Resting State'"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:08:30.954951Z",
     "start_time": "2025-07-01T12:08:30.944867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import openephysextract.utilities\n",
    "importlib.reload(openephysextract.utilities)\n",
    "from openephysextract.utilities import spreadsheet\n",
    "\n",
    "animals = pd.read_excel(\n",
    "    os.path.join(master, 'notes', 'MICE_LIST_EEG.xlsx'), sheet_name='animals'\n",
    ")\n",
    "\n",
    "phenotypes = {}\n",
    "\n",
    "for _, row in animals.iterrows():\n",
    "    phenotypes[row['Animal ID']] = row['Phenotype']\n",
    "    \n",
    "phenotypes"
   ],
   "id": "7e15dd550a3ae11a",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openephysextract' has no attribute 'utilities'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mopenephysextract\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutilities\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m importlib\u001B[38;5;241m.\u001B[39mreload(\u001B[43mopenephysextract\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mutilities\u001B[49m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mopenephysextract\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutilities\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m spreadsheet\n\u001B[1;32m      5\u001B[0m animals \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_excel(\n\u001B[1;32m      6\u001B[0m     os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(master, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnotes\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMICE_LIST_EEG.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m), sheet_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124manimals\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      7\u001B[0m )\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'openephysextract' has no attribute 'utilities'"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:07:29.923535Z",
     "start_time": "2025-07-01T12:07:29.912111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "importlib.reload(openephysextract.utilities)\n",
    "from openephysextract.utilities import spreadsheet\n",
    "\n",
    "notes = spreadsheet(\n",
    "    location = os.path.join(master, 'notes'),\n",
    "    name = 'MICE_LIST_EEG.xlsx',\n",
    "    id = 'Session',\n",
    "    relevant = sorted(os.listdir(source)),\n",
    "    sheet = 'MEP'\n",
    ")\n",
    "\n",
    "notes['group'] = notes['AnimalID'].map(phenotypes)\n",
    "\n",
    "notes"
   ],
   "id": "caf625949a5bb192",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openephysextract' has no attribute 'utilities'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m importlib\u001B[38;5;241m.\u001B[39mreload(\u001B[43mopenephysextract\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mutilities\u001B[49m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mopenephysextract\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutilities\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m spreadsheet\n\u001B[1;32m      4\u001B[0m notes \u001B[38;5;241m=\u001B[39m spreadsheet(\n\u001B[1;32m      5\u001B[0m     location \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(master, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnotes\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[1;32m      6\u001B[0m     name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMICE_LIST_EEG.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      9\u001B[0m     sheet \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMEP\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     10\u001B[0m )\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'openephysextract' has no attribute 'utilities'"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "1f8bd0d10694f81f",
   "metadata": {},
   "source": [
    "## I Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a38b51a8a0c357a",
   "metadata": {},
   "source": [
    "### I.I Extraction"
   ]
  },
  {
   "cell_type": "code",
   "id": "98fb375d10a268a0",
   "metadata": {},
   "source": [
    "import openephysextract.extractor\n",
    "importlib.reload(openephysextract.extractor)\n",
    "from openephysextract.extractor import Extractor\n",
    "\n",
    "extractor = Extractor(\n",
    "    source = source,\n",
    "    experiment = '5xFAD Resting State',\n",
    "    sampling_rate = 30000,\n",
    "    output = local_path,\n",
    "    notes = notes,\n",
    "    channels = [3, 4, 5, 6, 7, 8]\n",
    ")\n",
    "\n",
    "out = extractor.extractify(export = True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "out[0].summary_rate",
   "id": "5650519cd5c21a9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### I.II Preprocessing\n",
    "\n",
    "1, 2 primary motor cortex <br>\n",
    "3, 4 S1 L + R <br>\n",
    "5, 6 V1/V2 L + R <br>"
   ],
   "id": "dffd5f916f4a013f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:09:33.880926Z",
     "start_time": "2025-07-01T12:09:33.871183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import openephysextract.utilities\n",
    "importlib.reload(openephysextract.utilities)\n",
    "from openephysextract.utilities import loadify, savify"
   ],
   "id": "734a788e67ad1530",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openephysextract' has no attribute 'utilities'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mopenephysextract\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutilities\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m importlib\u001B[38;5;241m.\u001B[39mreload(\u001B[43mopenephysextract\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mutilities\u001B[49m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mopenephysextract\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutilities\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m loadify, savify\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'openephysextract' has no attribute 'utilities'"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "extracted = loadify('5xFAD Resting State RAW.pkl', local_path)",
   "id": "9a7517e8328e94e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "extracted[0].summary_rate",
   "id": "28fab76c40df7ad7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ee94664ae4731742",
   "metadata": {},
   "source": [
    "import openephysextract.preprocess\n",
    "importlib.reload(openephysextract.preprocess)\n",
    "from openephysextract.preprocess import (\n",
    "    Preprocessor,\n",
    "    RemoveBadStep,\n",
    "    FilterStep,\n",
    "    DownsampleStep,\n",
    "    EpochStep,\n",
    ")\n",
    "\n",
    "steps = [\n",
    "    RemoveBadStep(\n",
    "        std=True,            # use z-score of hybrid distance\n",
    "        alpha=0.5, beta=0.5, # as in your existing code\n",
    "        cutoff_percentile=90\n",
    "    ),\n",
    "    FilterStep(\n",
    "        lowcut=0.1,          # remove drift\n",
    "        highcut=80,          # up to your highest band\n",
    "        order=4,\n",
    "        notch_freqs=None,    # no notch\n",
    "        hp_cutoff=None,\n",
    "        detrend_data=False\n",
    "    ),\n",
    "    DownsampleStep(\n",
    "        target_fs=100        # e.g. 100 Hz Nyquist→50 Hz\n",
    "    ),\n",
    "    EpochStep(\n",
    "        frame=100,           # 1 s @100 Hz\n",
    "        stride=10,           # 90% overlap → 0.1 s steps\n",
    "        autoreject=False,    # skip any automatic rejection here\n",
    "        threshold=None,\n",
    "        consensus=None\n",
    "    ),\n",
    "]\n",
    "\n",
    "preprocessor = Preprocessor(\n",
    "    experiment=experiment,\n",
    "    sessions=extracted,\n",
    "    steps=steps,\n",
    "    destination=destination,    # we’ll keep in memory\n",
    "    summary_rate=100\n",
    ")\n",
    "\n",
    "preprocessed = preprocessor.preprocess(parallel=False, export=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "preprocessed[0]",
   "id": "ee9fe6c001ace43d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "30646aea3a8308e6",
   "metadata": {},
   "source": [
    "## II Analysis"
   ]
  },
  {
   "cell_type": "code",
   "id": "b4f6c3b0ed361264",
   "metadata": {},
   "source": "preprocessed[0].data.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eecd4db0f5d728d",
   "metadata": {},
   "source": [
    "### II.I PSD Analysis"
   ]
  },
  {
   "cell_type": "code",
   "id": "89f5a064c631737f",
   "metadata": {},
   "source": [
    "import openephysextract.analysis\n",
    "importlib.reload(openephysextract.analysis)\n",
    "from openephysextract.analysis import bandpower\n",
    "\n",
    "features = [bandpower(session) for session in preprocessed]\n",
    "\n",
    "savify(features, destination, 'features')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "features = loadify(output_2, 'features')",
   "id": "d315be3a6779c55",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9946afc956aed59f",
   "metadata": {},
   "source": [
    "### II.II Logistic Scaling (Garwood et. al)"
   ]
  },
  {
   "cell_type": "code",
   "id": "e946a8c2aa7b9adb",
   "metadata": {},
   "source": [
    "import openephysextract.analysis\n",
    "importlib.reload(openephysextract.analysis)\n",
    "from openephysextract.analysis import logistic_scaler as scaler\n",
    "\n",
    "scaled = [scaler(trial) for trial in features]\n",
    "\n",
    "savify(scaled, output_2, \"logistic-scaled\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a41512c077327c05",
   "metadata": {},
   "source": [
    "scaled = loadify(output_2, \"logistic-scaled\")\n",
    "scaled[0].data.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8dfd0930-1033-4504-980d-d3b5c3f3af9b",
   "metadata": {},
   "source": [
    "import openephysextract.plot\n",
    "importlib.reload(openephysextract.plot)\n",
    "from openephysextract.plot import plotifyEEGbands\n",
    "\n",
    "plotifyEEGbands(scaled[0])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "importlib.reload(openephysextract.utilities)\n",
    "from openephysextract.utilities import spreadsheet\n",
    "\n",
    "notes = spreadsheet(\n",
    "    location = '/Users/fomo/Documents/Research/UNIC Research/Motor Evoked Potentials/notes',\n",
    "    name = 'MICE_LIST_EEG.xlsx',\n",
    "    id = 'Session',\n",
    "    relevant = [trial.trial for trial in scaled],\n",
    "    sheet = 'MEP'\n",
    ")\n",
    "\n",
    "notes['group'] = notes['AnimalID'].map(phenotypes)\n",
    "\n",
    "for trial in scaled:\n",
    "    info = notes[notes['Session'] == trial.trial].iloc[0].to_dict()\n",
    "    trial.add_notes(info)\n",
    "    \n",
    "savify(scaled, output_2, 'logistic-scaled-with-notes')"
   ],
   "id": "86025085a568869f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## III beta-HMM Construction",
   "id": "504fb16815de6732"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### III.I ",
   "id": "c61ddd97af05752a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "from scipy.stats import beta\n",
    "from tqdm import tqdm\n",
    "\n",
    "class BetaHMM:\n",
    "    \"\"\"\n",
    "    Hidden Markov Model with beta emission distributions.\n",
    "    Optimized for vectorized forward/backward and EM convergence.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_states, n_features, seed=None):\n",
    "        self.K = n_states\n",
    "        self.D = n_features\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "        # model parameters\n",
    "        self.pi = self.rng.dirichlet(np.ones(self.K))               # initial state distribution\n",
    "        self.A  = self.rng.dirichlet(np.ones(self.K), size=self.K)  # transition matrix\n",
    "        # beta parameters to ensure unimodal; will be re-estimated\n",
    "        self.alpha = self.rng.uniform(1.5, 3.0, size=(self.K, self.D))\n",
    "        self.beta  = self.rng.uniform(1.5, 3.0, size=(self.K, self.D))\n",
    "\n",
    "    def _compute_ll(self, Y):\n",
    "        \"\"\"\n",
    "        Compute log-likelihood matrix of shape (N, K).\n",
    "        \"\"\"\n",
    "        Y = np.clip(Y, 1e-6, 1 - 1e-6)\n",
    "        return np.stack([\n",
    "            np.sum(beta.logpdf(Y, self.alpha[k], self.beta[k]), axis=1)\n",
    "            for k in range(self.K)\n",
    "        ], axis=1)\n",
    "\n",
    "    def _forward(self, LL, log_pi, log_A):\n",
    "        N, K = LL.shape\n",
    "        log_alpha = np.zeros((N, K))\n",
    "        log_alpha[0] = log_pi + LL[0]\n",
    "        for n in range(1, N):\n",
    "            log_alpha[n] = LL[n] + logsumexp(log_alpha[n-1][:, None] + log_A, axis=0)\n",
    "        return log_alpha\n",
    "\n",
    "    def _backward(self, LL, log_A):\n",
    "        N, K = LL.shape\n",
    "        log_beta = np.zeros((N, K))\n",
    "        for n in range(N-2, -1, -1):\n",
    "            log_beta[n] = logsumexp(\n",
    "                log_A + LL[n+1][None, :] + log_beta[n+1][None, :],\n",
    "                axis=1\n",
    "            )\n",
    "        return log_beta\n",
    "\n",
    "    def _compute_gamma_xi(self, log_alpha, log_beta, LL, log_A):\n",
    "        N, K = log_alpha.shape\n",
    "        # gamma: posterior state marginals\n",
    "        log_gamma = log_alpha + log_beta\n",
    "        log_gamma -= logsumexp(log_gamma, axis=1, keepdims=True)\n",
    "        gamma = np.exp(log_gamma)\n",
    "\n",
    "        # xi: posterior transition counts\n",
    "        xi = np.zeros((N-1, K, K))\n",
    "        for n in range(N-1):\n",
    "            log_xi_raw = (\n",
    "                    log_alpha[n][:, None] + log_A +\n",
    "                    LL[n+1][None, :] + log_beta[n+1][None, :]\n",
    "            )\n",
    "            log_xi = log_xi_raw - logsumexp(log_xi_raw)\n",
    "            xi[n] = np.exp(log_xi)\n",
    "        return gamma, xi\n",
    "\n",
    "    def em_step(self, Y):\n",
    "        LL      = self._compute_ll(Y)\n",
    "        log_pi  = np.log(np.clip(self.pi, 1e-12, 1.0))\n",
    "        log_A   = np.log(np.clip(self.A,  1e-12, 1.0))\n",
    "        log_a   = self._forward(LL, log_pi, log_A)\n",
    "        log_b   = self._backward(LL, log_A)\n",
    "        gamma, xi = self._compute_gamma_xi(log_a, log_b, LL, log_A)\n",
    "\n",
    "        # M-step: update pi and A\n",
    "        self.pi = gamma[0]\n",
    "        A_counts = xi.sum(axis=0)\n",
    "        self.A = A_counts / A_counts.sum(axis=1, keepdims=True)\n",
    "\n",
    "        # update beta parameters via weighted moments\n",
    "        for k in range(self.K):\n",
    "            w = gamma[:, k]\n",
    "            w_sum = w.sum()\n",
    "            if w_sum < 1e-8:\n",
    "                continue\n",
    "            mean = (w[:, None] * Y).sum(axis=0) / w_sum\n",
    "            var  = (w[:, None] * (Y - mean)**2).sum(axis=0) / w_sum\n",
    "            var  = np.clip(var, 1e-4, None)\n",
    "            v    = np.maximum(mean * (1 - mean) / var - 1, 1e-2)\n",
    "            self.alpha[k] = np.clip(mean * v,     1e-2, 1e2)\n",
    "            self.beta[k]  = np.clip((1 - mean)*v, 1e-2, 1e2)\n",
    "\n",
    "        return logsumexp(log_a[-1])\n",
    "\n",
    "    def fit(self, Y, max_iters=100, tol=1e-4):\n",
    "        \"\"\"\n",
    "        Run EM until convergence or max iterations on a single sequence.\n",
    "        \"\"\"\n",
    "        prev_ll = -np.inf\n",
    "        for _ in range(max_iters):\n",
    "            ll = self.em_step(Y)\n",
    "            if ll - prev_ll < tol:\n",
    "                break\n",
    "            prev_ll = ll\n",
    "        return self\n",
    "\n",
    "    def fit_multi(self, Y_list, max_iters=50, tol=1e-4):\n",
    "        \"\"\"\n",
    "        Fit a single Beta-HMM across multiple independent sequences.\n",
    "        \"\"\"\n",
    "        prev_ll = -np.inf\n",
    "\n",
    "        for _ in tqdm(range(max_iters)):\n",
    "            total_ll = 0.0\n",
    "            # Reset accumulators each iteration\n",
    "            pi_acc      = np.zeros(self.K)\n",
    "            A_acc       = np.zeros((self.K, self.K))\n",
    "            sum_weight  = np.zeros(self.K)\n",
    "            sum_Y       = np.zeros((self.K, self.D))\n",
    "            sum_Y2      = np.zeros((self.K, self.D))\n",
    "\n",
    "            # E-step: loop over trials\n",
    "            for Y in Y_list:\n",
    "                LL      = self._compute_ll(Y)\n",
    "                log_pi  = np.log(np.clip(self.pi, 1e-12, 1.0))\n",
    "                log_A   = np.log(np.clip(self.A,  1e-12, 1.0))\n",
    "                log_a   = self._forward(LL, log_pi, log_A)\n",
    "                log_b   = self._backward(LL, log_A)\n",
    "                gamma, xi = self._compute_gamma_xi(log_a, log_b, LL, log_A)\n",
    "\n",
    "                total_ll += logsumexp(log_a[-1])\n",
    "                pi_acc   += gamma[0]\n",
    "                A_acc    += xi.sum(axis=0)\n",
    "\n",
    "                for k in range(self.K):\n",
    "                    w = gamma[:, k]\n",
    "                    sum_weight[k] += w.sum()\n",
    "                    sum_Y[k]      += (w[:, None] * Y).sum(axis=0)\n",
    "                    sum_Y2[k]     += (w[:, None] * (Y**2)).sum(axis=0)\n",
    "\n",
    "            # M-step: update shared parameters\n",
    "            self.pi = pi_acc / pi_acc.sum()\n",
    "            self.A  = A_acc  / A_acc.sum(axis=1, keepdims=True)\n",
    "\n",
    "            for k in range(self.K):\n",
    "                mean = sum_Y[k] / sum_weight[k]\n",
    "                var  = (sum_Y2[k] / sum_weight[k]) - mean**2\n",
    "                var  = np.clip(var, 1e-4, None)\n",
    "                prec = np.maximum(mean * (1 - mean) / var - 1, 1e-2)\n",
    "                self.alpha[k] = np.clip(mean * prec,     1e-2, 1e2)\n",
    "                self.beta[k]  = np.clip((1 - mean)*prec, 1e-2, 1e2)\n",
    "\n",
    "            if total_ll - prev_ll < tol:\n",
    "                break\n",
    "            prev_ll = total_ll\n",
    "\n",
    "        return self\n",
    "\n",
    "    def viterbi(self, Y):\n",
    "        \"\"\"\n",
    "        Decode one sequence into its most likely state path.\n",
    "        \"\"\"\n",
    "        LL    = self._compute_ll(Y)\n",
    "        N, K  = LL.shape\n",
    "        delta = np.zeros((N, K))\n",
    "        psi   = np.zeros((N, K), dtype=int)\n",
    "\n",
    "        delta[0] = np.log(np.clip(self.pi, 1e-12, 1.0)) + LL[0]\n",
    "        log_A    = np.log(np.clip(self.A, 1e-12, 1.0))\n",
    "\n",
    "        for n in range(1, N):\n",
    "            scores     = delta[n-1][:, None] + log_A\n",
    "            psi[n]     = np.argmax(scores, axis=0)\n",
    "            delta[n]   = scores[psi[n], range(K)] + LL[n]\n",
    "\n",
    "        states = np.zeros(N, dtype=int)\n",
    "        states[-1] = np.argmax(delta[-1])\n",
    "        for n in range(N-2, -1, -1):\n",
    "            states[n] = psi[n+1, states[n+1]]\n",
    "\n",
    "        return states\n",
    "\n",
    "    def viterbi_multi(self, Y_list):\n",
    "        \"\"\"\n",
    "        Decode each sequence in Y_list independently.\n",
    "        \"\"\"\n",
    "        return [self.viterbi(Y) for Y in Y_list]\n"
   ],
   "id": "a394772a298f8f91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### III.II Model Order Selection",
   "id": "7e0c1d1a6ba17402"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "trials = loadify(output_2, 'logistic-scaled-with-notes')",
   "id": "c80dad3f63f0f1ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Ys = [t.data.reshape(t.data.shape[0], -1) for t in trials]",
   "id": "e1cc026356be8596",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bic_scores = []\n",
    "\n",
    "models = {}\n",
    "\n",
    "Ks = range(2, 16)\n",
    "for K in Ks:\n",
    "    model = BetaHMM(n_states=K, n_features=Ys[0].shape[1], seed=0)\n",
    "    model.fit_multi(Ys)\n",
    "    ll = sum(model._compute_ll(Y).max(axis=1).sum() for Y in Ys)  # or store EM log-likelihood\n",
    "    N_total = sum(Y.shape[0] for Y in Ys)\n",
    "\n",
    "    p = (K - 1) + K*(K - 1) + 2 * K * model.D\n",
    "    bic = -2 * ll + p * np.log(N_total)\n",
    "    bic_scores.append(bic)\n",
    "    \n",
    "    models[K] = model\n",
    "    \n",
    "best_K = Ks[np.argmin(bic_scores)]\n",
    "colors = ['red' if i == best_K else 'gray' for i in range(len(Ks))]\n",
    "\n",
    "plt.figure(figsize=(21, 7), dpi = 210)\n",
    "plt.bar(Ks, bic_scores, color=colors)\n",
    "plt.xlabel('Number of States (K)')\n",
    "plt.ylabel('BIC')\n",
    "plt.title('Model Selection via BIC')\n",
    "plt.xticks(Ks)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "savify(models, output_2, 'beta_hmm_models')"
   ],
   "id": "513059c532dbbcc6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_K, bic_scores, models",
   "id": "3247cd101e308313",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "models = loadify(output_2, 'beta_hmm_models')",
   "id": "4501a077c1019442",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "states = {}\n",
    "for K, model in tqdm(models.items()):\n",
    "    K = int(K)\n",
    "    states[K] = model.viterbi_multi(Ys)"
   ],
   "id": "9ce7dbc97b78b086",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### III.III Visualising Dynamics",
   "id": "6e79747cc1fb7f12"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### III.III.I State Trajectory",
   "id": "6845057694fbb476"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def find_most_consistent_state(seqs):\n",
    "    \"\"\"\n",
    "    Given a list of integer state sequences (each of length T_i),\n",
    "    find the state k whose first‐entry times (across trials that visit it)\n",
    "    have the smallest variance.\n",
    "    \"\"\"\n",
    "    first_times = {}\n",
    "    for seq in seqs:\n",
    "        for k in np.unique(seq):\n",
    "            idx = np.where(seq == k)[0]\n",
    "            if idx.size:\n",
    "                first_times.setdefault(k, []).append(idx[0])\n",
    "    # only consider states seen in at least half the trials\n",
    "    n_trials = len(seqs)\n",
    "    cons = {}\n",
    "    for k, times in first_times.items():\n",
    "        if len(times) >= n_trials/2:\n",
    "            cons[k] = np.var(times)\n",
    "    if not cons:\n",
    "        return None\n",
    "    return min(cons, key=cons.get)\n",
    "\n",
    "def align_on_state(seqs, state, window):\n",
    "    \"\"\"\n",
    "    Align each seq at its first entry into `state`, take exactly `window` steps after.\n",
    "    \"\"\"\n",
    "    aligned = []\n",
    "    for seq in seqs:\n",
    "        idx = np.where(seq == state)[0]\n",
    "        if idx.size:\n",
    "            start = idx[0]\n",
    "            if start + window <= len(seq):\n",
    "                aligned.append(seq[start:start+window])\n",
    "    return np.stack(aligned) if aligned else np.empty((0,window),dtype=int)"
   ],
   "id": "e49a874a2d0fcc41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "Ks = [2, 3, 4, 8]\n",
    "trial = 5\n",
    "sequence = states[K][trial]\n",
    "n_epochs = 500"
   ],
   "id": "422455ccdb363fed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "colors = sns.color_palette('Set2', len(Ks))\n",
    "\n",
    "phenotypes   = sorted({ tr.notes['group'] for tr in trials })\n",
    "colors       = sns.color_palette('Set2', len(phenotypes))\n",
    "\n",
    "fig, axs = plt.subplots(len(Ks), 1, figsize=(21, 3*len(Ks)), sharex=True, dpi = 210)\n",
    "\n",
    "for ax, K in zip(axs, Ks):\n",
    "    for ph, color in zip(phenotypes, colors):\n",
    "        # pick out only those trials of this phenotype\n",
    "        idxs      = [i for i,tr in enumerate(trials) if tr.notes['group']==ph]\n",
    "        ph_seqs   = [states[K][i] for i in idxs]\n",
    "\n",
    "        # find the best “anchor” \n",
    "        # state & align\n",
    "        best_st   = find_most_consistent_state(ph_seqs)\n",
    "        if best_st is None:\n",
    "            continue\n",
    "\n",
    "        aligned   = align_on_state(ph_seqs, best_st, n_epochs)\n",
    "        if aligned.size == 0:\n",
    "            continue\n",
    "\n",
    "        # compute the across‐trial mode path\n",
    "        mode_path = mode(aligned, axis=0).mode.flatten()\n",
    "        ax.plot(mode_path,\n",
    "                lw=3.0,\n",
    "                label=ph,\n",
    "                color=color)\n",
    "\n",
    "    ax.set_ylabel(f'K={K}\\nstate', fontsize=12)\n",
    "    ax.set_yticks(range(K))\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax.legend(title='Phenotype')\n",
    "\n",
    "axs[-1].set_xlabel('Epochs after alignment', fontsize=14)\n",
    "plt.suptitle('Mode Viterbi Paths by Phenotype (aligned on each group’s most‐consistent state)',\n",
    "             y=1.02,\n",
    "             fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "3ac7fdf92656e27a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### III.III.II State Occupancy + Dwell Times",
   "id": "c8ad02deca13cac0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "\n",
    "rows = []\n",
    "\n",
    "groups = sorted({trial.notes['group'] for trial in trials})\n",
    "\n",
    "Ks_sorted = sorted(states.keys())\n",
    "\n",
    "for K, trial_seqs in states.items():\n",
    "    for group in groups:\n",
    "        occ_accum   = {k: [] for k in range(K)}\n",
    "        dwell_accum = {k: [] for k in range(K)}\n",
    "\n",
    "        for i, seq in enumerate(trial_seqs):\n",
    "            if trials[i].notes['group'] != group:\n",
    "                continue\n",
    "\n",
    "            # Occupancy: fraction of time in each state\n",
    "            for k in range(K):\n",
    "                occ_accum[k].append(np.mean(seq == k))\n",
    "\n",
    "            # Dwell time: mean length of each visit to each state\n",
    "            for k_run, g in itertools.groupby(seq):\n",
    "                if k_run in dwell_accum:\n",
    "                    dwell_accum[k_run].append(len(list(g)))\n",
    "\n",
    "        # Store mean across trials\n",
    "        for k in range(K):\n",
    "            rows.append({\n",
    "                'K': K,\n",
    "                'group': group,\n",
    "                'state': k,\n",
    "                'occupancy': np.mean(occ_accum[k]) if occ_accum[k] else 0,\n",
    "                'dwell_time': np.mean(dwell_accum[k]) if dwell_accum[k] else 0\n",
    "            })\n",
    "\n",
    "# Final tidy DataFrame\n",
    "metrics = pd.DataFrame(rows)\n",
    "metrics.head()\n",
    "\n",
    "groups_sorted = sorted(metrics['group'].unique())\n",
    "states_all = sorted(metrics['state'].unique())\n",
    "state_colors = sns.color_palette('tab20', len(states_all))"
   ],
   "id": "88d6662752cde011",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_metric(metric_name, ylabel, title):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    bar_width = 0.35\n",
    "    x_pos = np.arange(len(Ks_sorted))\n",
    "\n",
    "    handles = []\n",
    "\n",
    "    for gi, group in enumerate(groups_sorted):\n",
    "        offset = (gi - 0.5) * bar_width  # side-by-side bars per K\n",
    "        hatch = '///' if group == '5XFAD' else ''  # differentiate group visually\n",
    "        alpha = 0.9 if group == 'WT' else 0.6       # optional: use transparency too\n",
    "\n",
    "        for ki, K in enumerate(Ks_sorted):\n",
    "            df_sub = metrics[(metrics['K'] == K) & (metrics['group'] == group)]\n",
    "            df_sub = df_sub.sort_values('state')\n",
    "\n",
    "            bottom = 0\n",
    "            for _, row in df_sub.iterrows():\n",
    "                state_idx = row['state']\n",
    "                height = row[metric_name]\n",
    "                color = state_colors[state_idx]\n",
    "\n",
    "                bar = ax.bar(\n",
    "                    x=x_pos[ki] + offset,\n",
    "                    height=height,\n",
    "                    bottom=bottom,\n",
    "                    width=bar_width,\n",
    "                    color=color,\n",
    "                    hatch=hatch,\n",
    "                    alpha=alpha,\n",
    "                    edgecolor='black' if state_idx == 0 else None,\n",
    "                    label=f\"{group} — State {state_idx}\"\n",
    "                )\n",
    "                bottom += height\n",
    "\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(Ks_sorted)\n",
    "    ax.set_xlabel('Number of States (K)')\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "    # custom legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "\n",
    "    ax.legend(\n",
    "        by_label.values(),\n",
    "        by_label.keys(),\n",
    "        bbox_to_anchor=(1.02, 1),\n",
    "        loc='upper left',\n",
    "        title='Group — State',\n",
    "        borderaxespad=0.\n",
    "    )\n",
    "\n",
    "    # Give extra room on the right for the legend\n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    plt.show()"
   ],
   "id": "39356affb6b8dcf3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_metric(\n",
    "    metric_name='occupancy',\n",
    "    ylabel='Average Occupancy',\n",
    "    title='Average State Occupancy by Group (stacked by state)'\n",
    ")"
   ],
   "id": "fd3308e93828b1c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_metric(\n",
    "    metric_name='dwell_time',\n",
    "    ylabel='Mean Dwell Time (epochs)',\n",
    "    title='Average State Dwell Time by Group (stacked by state)'\n",
    ")"
   ],
   "id": "1bb472be3a06388f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### III.III.III Transition matrix heatmap",
   "id": "4314c4ddc5e6f744"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# --- Select specific Ks ---\n",
    "Ks_selected = [2, 3, 4, 8]  # replace with your desired Ks\n",
    "phenotypes = sorted({trial.notes['group'] for trial in trials})\n",
    "n_K = len(Ks_selected)\n",
    "n_G = len(phenotypes)\n",
    "\n",
    "# Helper: Estimate transition matrix from list of sequences\n",
    "def estimate_transition_matrix(seqs, K):\n",
    "    A = np.zeros((K, K))\n",
    "    for seq in seqs:\n",
    "        for i, j in zip(seq[:-1], seq[1:]):\n",
    "            A[i, j] += 1\n",
    "    row_sums = A.sum(axis=1, keepdims=True)\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        A = np.divide(A, row_sums, where=row_sums != 0)\n",
    "    return A\n",
    "\n",
    "# Create subplot grid: rows = phenotypes, cols = selected Ks\n",
    "fig, axes = plt.subplots(n_G, n_K, figsize=(4 * n_K, 4 * n_G))\n",
    "\n",
    "for row, group in enumerate(phenotypes):\n",
    "    for col, K in enumerate(Ks_selected):\n",
    "        ax = axes[row, col] if n_G > 1 else axes[col]\n",
    "\n",
    "        # Get sequences of this group at this K\n",
    "        seqs = [seq for seq, trial in zip(states[K], trials) if trial.notes['group'] == group]\n",
    "\n",
    "        if len(seqs) == 0:\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "\n",
    "        A = estimate_transition_matrix(seqs, K)\n",
    "        sns.heatmap(A, annot=True, fmt='.2f', cbar=False, ax=ax,\n",
    "                    vmin=0, vmax=1, square=True, cmap='viridis')\n",
    "\n",
    "        ax.set_title(f'K={K}', fontsize=10)\n",
    "        ax.set_xlabel('to')\n",
    "        if col == 0:\n",
    "            ax.set_ylabel(f'{group}\\nfrom', fontsize=10)\n",
    "        else:\n",
    "            ax.set_ylabel(\"\")\n",
    "\n",
    "# Layout tweaks\n",
    "plt.suptitle('Transition Matrices by Phenotype (Selected K)', fontsize=16, y=1.03)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "6d849e04baad3317",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Other",
   "id": "791ebb81620801a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "names = [trial.trial for trial in scaled]\n",
   "id": "e7e716856bbfd7e7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
